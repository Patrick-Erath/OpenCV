{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECSE415 - Intro to Computer Vision\n",
    "## Tutorial 9 - Introduction to Machine Learning  using Scikit-Learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A machine learning problem consists of $n$ instances of data and attempts to predict properties of unseen data.\n",
    "\n",
    "Learning problems can be separated into several categories:\n",
    "* Supervised Learning: data comes with additional attributes that we want to predict. This problem can be either:\n",
    " * Classification: Samples belong to two or more classes and the algorithm learns from already labeled data to         predict to class of unseen data.\n",
    " * Regression: the desired output consists of one or more continuous variables.\n",
    "* Unsupervised Learning: data consists of a set of input vectors without any corresponding target values. Examples include clustering, density estimation, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data dimensions: (1797, 64)\n",
      "Output data dimensions: (1797,)\n",
      "Input data:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAA/CAYAAADAByJpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAABetJREFUeJzt3b0yNFsUxvE9p07u4wZ8XQDK5Kgi\nJiFFJCQjQ0aEkASxhJgq5BRuQHEDhiuYN+ta+3n1nunpbuesqv8v6q5mZk93z6rZT+/d3Wi32wEA\n4Mc//3UDAADFULgBwBkKNwA4Q+EGAGco3ADgDIUbAJyhcAOAMxRuAHCGwg0Azvxbx4s2Go3c6ZhL\nS0vR+v7+frZ8e3sbbdve3o7WW61W7nu22+1GkXao+/v7bLm/vz/atrOzE61fX1/X1o6ZmZls+erq\nKtr28vKS+7dl27G1tRWt2+Py9vYWbWs2m9F6ncfFHovz8/No2+LiYrcvU7gd9nwIIYT39/dseXV1\ntev3LduOVLv0PJ2YmKitHZubm9G6fW89DuPj49H69/d3tjw8PBxta7VahdpxdHQUrdv31vND//br\n6yvvZQvvD/1u2v2R+l528lM7fsIvbgBwhsINAM5QuAHAmVoy7hSbnYYQwujoaLY8MDAQbfv8/IzW\nl5eXs+XLy8tK22Xzr+np6Wjb7OxstJ7KuIvSXPLu7i5bttlgCH/ng2XZY6HXHtbX17Plk5OTaNvU\n1FS0rtcmqmTzZM3466T72p4TKysr0baPj4/k/5axsLCQ2469vb3K3qco+33R/DuVh6dy5m6kcny9\n9qBZc5nsOYT4uOpxsfSOq6+vr9F6kWsRefjFDQDOULgBwJlfiUps19pGIyGEMDY2li3rsLObm5vc\n1ykblWh3JdWNqrOLrkOpbLdKhxzpsMSyTk9Ps+WDg4No2+PjY7asx6XOaESHuNnurw7vSkUSdvhe\nL7RLPzQ0lC1rhKVDB6uMBlJxiJ4fddJ9b+3u7kbrelzKRhSWfhdTwzR139t26DHrhp6b1sPDw49t\n0vetCr+4AcAZCjcAOEPhBgBnfiXjtsP8np6eom2an1r6t2XZYUqay/X19eX+Xy95WLc0O7T5mG6r\nchhiCPG+12sPdl0zbR22mZryXpTmlDYvLTKlWY9vUZpT2mnceq5o7lo217Y0V7XXQOoeHmmz2VRO\nq8P/VGpaelH6/8/Pz9myZut6HMpe90j9v/2MqenwVeEXNwA4Q+EGAGd+PSopMpSs6i657Vprlyv1\n2lV3dezraTczdce7Mnel60Qjq8HBwWxZh2Xq+vz8fLbcyzGys9AODw+jbRcXF7n/t7GxEa2vra0V\nfu88ehxsVKBDSbXNVmoYXTf03LPddT13tIteZTRQZPis7rsqo8bUd1FnPI+MjETrVQ4R1dmQ9rw/\nPj6Otum+s5FOr23iFzcAOEPhBgBnKNwA4MyvZNw2/9E7y1maaevfVn1HwG5pRlV2GJYdqqY5raVZ\nYZXDzDqxx8xm2CH8fbdA+/QcfWpRN+wUcp1Obu/E1+muanVOAS+S01Z5d0DNQG2Oq3mvZu2Tk5PZ\nci/nrH1vPRftHfDqzLRDiI+7vXtmCPEtAXS/6/lg21k279Zz0a532tf2ukeRpzhZ/OIGAGco3ADg\nDIUbAJz5lYzbjhHW3No+eUWfwqL01qNe2THkOh7WTq3WjE6nvJ+dneVuK0qfTGTH2+u1h7m5uWi9\n7LWHbp9crtmpjvGu8hqAPuHEZu+dptNXmbXrfAObY2tOqxmvzU/LXpfR8eh2f9hbmtbBfk69BmLb\npZ/fTocPIZ4HUfaWCMruX91XOv+i11zb4hc3ADhD4QYAZ349KtHhYraLrncDbDabtbVJu9U2atBu\nssYZZe9wZrtVqWFF2p3TdtkuZNmoRKeq65A/S6MR+2DhqtnjpHflK3scUvQB0alhmxrZVDkcTj+j\njQO0C67vW2Vko98BO0yz7mGq9vX1M9rzVmMU/U6Uvf1A6rXs91bjPt13VdzVkV/cAOAMhRsAnKFw\nA4AzDTt1FQDw/8cvbgBwhsINAM5QuAHAGQo3ADhD4QYAZyjcAOAMhRsAnKFwA4AzFG4AcIbCDQDO\nULgBwBkKNwA4Q+EGAGco3ADgDIUbAJyhcAOAMxRuAHCGwg0AzlC4AcAZCjcAOEPhBgBnKNwA4AyF\nGwCc+QOehmSXGJyC+gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x272b0072b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output labels:\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "print(\"Input data dimensions:\", digits.data.shape)\n",
    "print(\"Output data dimensions:\", digits.target.shape)\n",
    "\n",
    "print(\"Input data:\")\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.imshow(digits.data[i].reshape(8,8), cmap='gray'); plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(\"Output labels:\")\n",
    "print(digits.target[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is to predict the output label (number from 0-9) for each input image. Since we are provided with examples of each of the 10 possible classes, we can now attempt to *fit* an estimator to be able to *predict* the classes to which unseen samples belong.\n",
    "\n",
    "We can begin by looking at a Support Vector Machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: [0 8 9 8]\n",
      "Actual Label: [0 8 9 8]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAB4CAYAAADSWhi9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDMENAMX8B206UeK467G+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x272b1b1c668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "clf = svm.SVC(gamma=0.001, C=100.)\n",
    "# another important argument:\n",
    "# class_weight : {dict, ‘balanced’}\n",
    "# tol : float, default=1e-3\n",
    "# max_iter : int, default=-1\n",
    "# kernel : string, default=’rbf’. You have mode options available. Check the documentation.\n",
    "        \n",
    "# training, let's us all the data but the last 4 instances\n",
    "clf.fit(digits.data[:-4], digits.target[:-4])\n",
    "# now predict the label for the last 2 instances\n",
    "print(\"Predicted Label:\", clf.predict(digits.data[-4:]))\n",
    "print(\"Actual Label:\", digits.target[-4:])\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "plt.subplot(141), plt.imshow(digits.data[-4].reshape(8,8), cmap='gray'); plt.axis('off')\n",
    "plt.subplot(142), plt.imshow(digits.data[-3].reshape(8,8), cmap='gray'); plt.axis('off')\n",
    "plt.subplot(143), plt.imshow(digits.data[-2].reshape(8,8), cmap='gray'); plt.axis('off')\n",
    "plt.subplot(144), plt.imshow(digits.data[-1].reshape(8,8), cmap='gray'); plt.axis('off')\n",
    "plt.title(\"Digits Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use LBP features for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: [0 8 9 2]\n",
      "Actual Label: [0 8 9 8]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAB4CAYAAADSWhi9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDMENAMX8B206UeK467G+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x272b20c2cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import local_binary_pattern\n",
    "import numpy as np\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "clf = svm.SVC(gamma=0.001, C=100.) # another important argument: class_weight : {dict, ‘balanced’}\n",
    "# training, let's us all the data but the last 4 instances\n",
    "\n",
    "features = []\n",
    "for i in range(digits.data.shape[0]):\n",
    "    features.append(local_binary_pattern(digits.data[i].reshape(8,8), 8, 1, method='uniform')) # data, P, R\n",
    "features = np.stack(features).reshape(-1, 64)\n",
    "\n",
    "clf.fit(features[:-4], digits.target[:-4])\n",
    "# now predict the label for the last 2 instances\n",
    "print(\"Predicted Label:\", clf.predict(features[-4:]))\n",
    "print(\"Actual Label:\", digits.target[-4:])\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "plt.subplot(141), plt.imshow(digits.data[-4].reshape(8,8), cmap='gray'); plt.axis('off')\n",
    "plt.subplot(142), plt.imshow(digits.data[-3].reshape(8,8), cmap='gray'); plt.axis('off')\n",
    "plt.subplot(143), plt.imshow(digits.data[-2].reshape(8,8), cmap='gray'); plt.axis('off')\n",
    "plt.subplot(144), plt.imshow(digits.data[-1].reshape(8,8), cmap='gray'); plt.axis('off')\n",
    "plt.title(\"Digits Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: [0 8 9 8]\n",
      "Actual Label: [0 8 9 8]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAB4CAYAAADSWhi9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDMENAMX8B206UeK467G+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x272b184e630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# training, let's us all the data but the last 4 instances\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "# Other important arguments:\n",
    "# min_samples_split : int, float, optional (default=2)\n",
    "# min_samples_leaf : int, float, optional (default=1)\n",
    "# max_features : int, float, string or None, optional (default=”auto”)\n",
    "# max_leaf_nodes : int or None, optional (default=None)\n",
    "\n",
    "clf.fit(digits.data[:-4], digits.target[:-4])\n",
    "# now predict the label for the last 2 instances\n",
    "print(\"Predicted Label:\", clf.predict(digits.data[-4:]))\n",
    "print(\"Actual Label:\", digits.target[-4:])\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "plt.subplot(141), plt.imshow(digits.data[-4].reshape(8,8), cmap='gray'); plt.axis('off')\n",
    "plt.subplot(142), plt.imshow(digits.data[-3].reshape(8,8), cmap='gray'); plt.axis('off')\n",
    "plt.subplot(143), plt.imshow(digits.data[-2].reshape(8,8), cmap='gray'); plt.axis('off')\n",
    "plt.subplot(144), plt.imshow(digits.data[-1].reshape(8,8), cmap='gray'); plt.axis('off')\n",
    "plt.title(\"Digits Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit learn also lets you save your best model to disk for future uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(clf, 'filename.pk1')\n",
    "\n",
    "# load back the pickled model at a later time\n",
    "clf = joblib.load('filename.pk1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also update and fine-tune hyper-parameters after the model has been constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Kernel:\n",
      "\tPredicted Labels: [5 4 8 8 4 9 0 8 9 8]\n",
      "\tActual Labels:    [5 4 8 8 4 9 0 8 9 8]\n",
      "\n",
      "Radial Basis Function Kernel:\n",
      "\tPredicted Labels: [5 4 5 5 4 9 5 5 5 5]\n",
      "\tActual Labels:    [5 4 8 8 4 9 0 8 9 8]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "# classifer object\n",
    "clf = svm.SVC()\n",
    "# set hyper-parameters\n",
    "print(\"Linear Kernel:\")\n",
    "clf.set_params(kernel='linear').fit(digits.data[:-10], digits.target[:-10])\n",
    "print(\"\\tPredicted Labels:\", clf.predict(digits.data[-10:]))\n",
    "print(\"\\tActual Labels:   \", digits.target[-10:])\n",
    "print(\"\")\n",
    "\n",
    "print(\"Radial Basis Function Kernel:\")\n",
    "clf.set_params(kernel='rbf').fit(digits.data[:-10], digits.target[:-10])\n",
    "print(\"\\tPredicted Labels:\", clf.predict(digits.data[-10:]))\n",
    "print(\"\\tActual Labels:   \", digits.target[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit learn also supports multiclass and mutlilabel fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 4, 3, 3, 4, 9, 0, 3, 9, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "X_train = digits.data[:-10]\n",
    "y_train = digits.target[:-10]\n",
    "X_test = digits.data[-10:]\n",
    "y_test = digits.target[-10:]\n",
    "\n",
    "classif = OneVsRestClassifier(estimator = SVC(random_state=0))\n",
    "classif.fit(X_train, y_train).predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In the above case, the classifier is fit on a 1d array of multiclass labels and the **predict()** method therefore provides corresponding multiclass predictions. It is also possible to fit upon a 2d array of binary label indicators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: \n",
      " [5 4 8 8 4 9 0 8 9 8]\n",
      "Predicted label: \n",
      " [[0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "classif = OneVsRestClassifier(estimator = SVC(gamma=0.001, C=100., random_state=0))\n",
    "y_train_binary = LabelBinarizer().fit_transform(y_train)\n",
    "y_test_predicted = classif.fit(X_train, y_train_binary).predict(X_test)\n",
    "\n",
    "print('True label: \\n', y_test)\n",
    "print('Predicted label: \\n', y_test_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the classifier is **fit()** on a 2d binary representation of **y** using the **LabelBinarizer**. In this case **predict()** returns a 2d array representing the corresponding multilabel predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binarized labels:\n",
      " [[1 1 0 0 0]\n",
      " [1 0 1 0 0]\n",
      " [0 1 0 1 0]\n",
      " [1 0 1 1 0]\n",
      " [0 0 1 0 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0, 0],\n",
       "       [1, 0, 1, 0, 0],\n",
       "       [1, 0, 1, 1, 0],\n",
       "       [1, 0, 1, 0, 0],\n",
       "       [1, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "X = [[1, 2], [2, 4], [4, 5], [3, 2], [3, 1]]\n",
    "y = [[0, 1], [0, 2], [1, 3], [0, 2, 3], [2, 4]]\n",
    "y = MultiLabelBinarizer().fit_transform(y)\n",
    "print('Binarized labels:\\n', y)\n",
    "classif.fit(X, y).predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the classifier is fit upon instances each assigned multiple labels. The **MultiLabelBinarizer** is used to binarize the 2d array of multilabels to **fit** upon. As a result, **predict()** returns a 2d array with multiple predicted labels for each instance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
